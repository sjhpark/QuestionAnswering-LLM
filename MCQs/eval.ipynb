{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/QA_llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter, NLTKTextSplitter, SpacyTextSplitter\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name:str):\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def measure_accuracy(LLM, prompt, Q, A, RAG:bool=False):\n",
    "    correct_count = 0\n",
    "    wrong_count = 0\n",
    "    unsure_count = 0\n",
    "    for q,a in tqdm(zip(Q, A), total=len(Q), desc=\"Measuring Accuracy\"):\n",
    "        if RAG:\n",
    "            pred = LLM.invoke(prompt + q)['result']\n",
    "        else:\n",
    "            pred = LLM.invoke(prompt + q).content\n",
    "        pred = pred.strip()[0]\n",
    "        print(f\"Correct Answer: {a}, Predicted Answer: {pred}\")\n",
    "\n",
    "        if pred == 'X': # if the answer is X (don't know)\n",
    "            unsure_count += 1\n",
    "        else:\n",
    "            if a == pred:\n",
    "                correct_count += 1\n",
    "            else:\n",
    "                wrong_count += 1\n",
    "    print(colored(f\"Correct: {correct_count}/{len(Q)}\", 'green'))\n",
    "    print(colored(f\"Wrong: {wrong_count}/{len(Q)}\", 'red'))\n",
    "    print(colored(f\"Unsure: {unsure_count}/{len(Q)}\", 'yellow'))\n",
    "    return correct_count, wrong_count, unsure_count\n",
    "        \n",
    "\n",
    "def get_llm_config(params:dict):\n",
    "    LLM_name = \"mistral:instruct\" # https://ollama.com/library/mistral:instruct\n",
    "    LLM = ChatOllama(model=LLM_name, temperature=params['temperature'])\n",
    "    params['llm'] = LLM_name\n",
    "    params['is_hf'] = False\n",
    "    return LLM, params\n",
    "\n",
    "def get_llm(params:dict):\n",
    "    LLM, config = get_llm_config(params)\n",
    "    if params['is_hf']:\n",
    "        pipe = pipeline(\n",
    "            task = params['task'],\n",
    "            model = LLM,\n",
    "            tokenizer = params['tokenizer'],\n",
    "            pad_token_id = params['tokenizer'].eos_token_id,\n",
    "            max_length = params['max_length'],\n",
    "            temperature = params['temperature'],\n",
    "            do_sample = params['do_sample'] if params['task'] == 'text2text-generation' else None,\n",
    "            top_p = params['top_p'] if params['task'] == 'text-generation' else None,\n",
    "            repetition_penalty = params['repetition_penalty']\n",
    "            )\n",
    "        LLM = HuggingFacePipeline(pipeline = pipe)\n",
    "    return LLM, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Choce Questions (MCQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCQs about Omicron\n",
    "MCQs_omicrons = read_csv(\"MCQs_omicron.csv\")\n",
    "MCQs_omicrons_Q = MCQs_omicrons['Q']\n",
    "MCQs_omicrons_A = MCQs_omicrons['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "params = {\n",
    "    'chain_type': 'stuff',\n",
    "    'embedding_device': 'cuda',\n",
    "    'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'k': 3,\n",
    "    'llm': 'google/flan-t5-base',\n",
    "    'llm_device': 'cuda',\n",
    "    'max_length': 2000,\n",
    "    'quantize': True,\n",
    "    'query_instruction': 'Represent the question for retrieving supporting documents',\n",
    "    'repetition_penalty': 1.0,\n",
    "    'search_type': 'similarity',\n",
    "    'separator': '\\n\\n',\n",
    "    'temperature': 0.05,\n",
    "    'top_p': 1.0,\n",
    "    'chunk_size': 500,\n",
    "    'chunk_overlap': 0,\n",
    "}\n",
    "\n",
    "# engineered prompt template\n",
    "prompt = \"\"\"You are the angent that has to select the correct answer to the following multiple choice question in the context provided.\n",
    "            You cannot speak human language, but you can only say one single letter.\n",
    "            Choose the letter corresponding to the correct answer.\n",
    "            If you don't know or unsure about the answer, just display the letter X without any additional text.\n",
    "            If you know the answer, display the letter corresponding to the correct answer without any additional text.\n",
    "            Whether you know or don't know the answer, do not display any other texts except for the letter.\n",
    "            Your response always has to be just one single letter.\n",
    "            Example of the answer that you have to say: A.\n",
    "            Context is: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMCQ Generator LLM: model='mistral:instruct' temperature=0.05\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Large Language Model (LLM)\n",
    "LLM, _ = get_llm(params)\n",
    "print(colored(f\"MCQ Generator LLM: {LLM}\", \"yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:   4%|▍         | 1/25 [00:09<03:50,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:   8%|▊         | 2/25 [00:21<04:11, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  12%|█▏        | 3/25 [00:35<04:30, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  16%|█▌        | 4/25 [00:45<04:03, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  20%|██        | 5/25 [00:52<03:12,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  24%|██▍       | 6/25 [01:02<03:08,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  28%|██▊       | 7/25 [01:14<03:11, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  32%|███▏      | 8/25 [01:21<02:40,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  36%|███▌      | 9/25 [01:34<02:51, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  40%|████      | 10/25 [01:43<02:31, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  44%|████▍     | 11/25 [01:53<02:20, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  48%|████▊     | 12/25 [02:04<02:13, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  52%|█████▏    | 13/25 [02:09<01:43,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  56%|█████▌    | 14/25 [02:21<01:48,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  60%|██████    | 15/25 [02:27<01:26,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  64%|██████▍   | 16/25 [02:36<01:17,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  68%|██████▊   | 17/25 [02:46<01:11,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  72%|███████▏  | 18/25 [02:54<01:01,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  76%|███████▌  | 19/25 [03:01<00:48,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  80%|████████  | 20/25 [03:13<00:47,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  84%|████████▍ | 21/25 [03:34<00:51, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  88%|████████▊ | 22/25 [03:44<00:36, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  92%|█████████▏| 23/25 [03:53<00:22, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  96%|█████████▌| 24/25 [04:02<00:10, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy: 100%|██████████| 25/25 [04:09<00:00,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n",
      "\u001b[32mCorrect: 11/25\u001b[0m\n",
      "\u001b[31mWrong: 2/25\u001b[0m\n",
      "\u001b[33mUnsure: 12/25\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy\n",
    "acc = measure_accuracy(LLM, prompt, MCQs_omicrons_Q, MCQs_omicrons_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter, NLTKTextSplitter, SpacyTextSplitter\n",
    "from langchain_community.vectorstores import Cassandra, Chroma, FAISS # vector database\n",
    "from utils import pdf_loader, docs_splitter, get_embeddings, \\\n",
    "                    build_database, get_retriever, get_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAG(pdf:str, params:dict):\n",
    "    # get LLM\n",
    "    LLM, config = get_llm(params)\n",
    "    # load document\n",
    "    pdf = os.path.join(\"../data\", pdf) # PDF file\n",
    "    assert pdf.endswith(\".pdf\"), \"Please provide a PDF document\"\n",
    "    loader = PyPDFLoader(pdf) # PDF loader\n",
    "    docs = loader.load() # load document\n",
    "    # split document\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=params['chunk_size'], chunk_overlap=params['chunk_overlap'], separators=params['separator'])\n",
    "    chunks = docs_splitter(text_splitter=text_splitter, docs=docs)\n",
    "    # get embeddings\n",
    "    embedding_model_wrapper = HuggingFaceInstructEmbeddings\n",
    "    embedding_model = params['embedding_model']\n",
    "    embeddings = get_embeddings(embedding_model_wrapper, embedding_model, device=params['embedding_device'], query_instruction=params['query_instruction'])\n",
    "    # build database\n",
    "    database = FAISS\n",
    "    db = build_database(database, chunks, embeddings)\n",
    "    # get retriever\n",
    "    retriever = get_retriever(db, search_type=params['search_type'], k=params['k'])\n",
    "    # get Q&A chain\n",
    "    qa_chain = get_qa_chain(LLM, retriever, chain_type=params['chain_type'])\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mDocument has been split into 31 chunks\u001b[0m\n",
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/QA_llm/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n",
      "\u001b[1m\u001b[32mEmbeddings have been generated using HuggingFaceInstructEmbeddings\u001b[0m\n",
      "\u001b[1m\u001b[32mBuilding FAISS vector database...\u001b[0m\n",
      "\u001b[1m\u001b[32mFAISS vector database has successfully been built\u001b[0m\n",
      "\u001b[1m\u001b[32mVector retriever has been created for similarity search\u001b[0m\n",
      "\u001b[1m\u001b[32mQ&A chain has been created\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pdf = \"Omicron Variant Symptoms and Treatment.pdf\"\n",
    "qa_chain = RAG(pdf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:   4%|▍         | 1/25 [00:10<04:22, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:   8%|▊         | 2/25 [00:13<02:20,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  12%|█▏        | 3/25 [00:17<01:54,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  16%|█▌        | 4/25 [00:38<03:58, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  20%|██        | 5/25 [00:39<02:32,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  24%|██▍       | 6/25 [00:51<02:53,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  28%|██▊       | 7/25 [01:03<02:59,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  32%|███▏      | 8/25 [01:31<04:27, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  36%|███▌      | 9/25 [01:40<03:40, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  40%|████      | 10/25 [01:54<03:24, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  44%|████▍     | 11/25 [02:17<03:52, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  48%|████▊     | 12/25 [02:28<03:12, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  52%|█████▏    | 13/25 [02:33<02:24, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  56%|█████▌    | 14/25 [02:36<01:40,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  60%|██████    | 15/25 [02:39<01:12,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  64%|██████▍   | 16/25 [03:10<02:10, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  68%|██████▊   | 17/25 [03:21<01:48, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  72%|███████▏  | 18/25 [04:10<02:49, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  76%|███████▌  | 19/25 [04:15<01:49, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  80%|████████  | 20/25 [04:30<01:26, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: B, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  84%|████████▍ | 21/25 [04:56<01:19, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  88%|████████▊ | 22/25 [05:00<00:45, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  92%|█████████▏| 23/25 [05:17<00:31, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:  96%|█████████▌| 24/25 [05:31<00:15, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: A, Predicted Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy: 100%|██████████| 25/25 [05:46<00:00, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: C, Predicted Answer: C\n",
      "\u001b[32mCorrect: 19/25\u001b[0m\n",
      "\u001b[31mWrong: 3/25\u001b[0m\n",
      "\u001b[33mUnsure: 3/25\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy\n",
    "acc = measure_accuracy(qa_chain, prompt, MCQs_omicrons_Q, MCQs_omicrons_A, RAG=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
