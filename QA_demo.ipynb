{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Large Language Model\n",
    "This LLM will be used as a head in a RAG pipeline to generate natural language fashion answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read second line in txt\n",
    "api_file = open(\"model_API_keys/palm_api.txt\", \"r\")\n",
    "api_key = api_file.readlines()[1] # read second line\n",
    "api_key = api_key.strip() # remove newline (\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/QA_llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pre-trained model\n",
    "model = GooglePalm(google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(model, question:str):\n",
    "    print(f\"Question: {question}\")\n",
    "    try:\n",
    "        answer = model(question)\n",
    "        print(f\"Answer:\\n{answer}\")\n",
    "    except:\n",
    "        print(\"Similarity search failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 3rd degree burns on palms, what to do?\n",
      "Similarity search failed.\n",
      "Question: What to do if you are tired?\n",
      "Answer:\n",
      "**1. Get enough sleep.** This is the most important thing you can do to avoid feeling tired. Most adults need around 7-8 hours of sleep per night. If you're not getting enough sleep, you'll likely feel tired during the day, even if you've had a cup of coffee.\n",
      "2. **Take breaks throughout the day.** If you're feeling tired, don't try to push through it. Take a break and do something relaxing, like reading, listening to music, or taking a short nap.\n",
      "3. **Eat healthy foods.** Eating a healthy diet can help you have more energy. Make sure to eat plenty of fruits, vegetables, and whole grains.\n",
      "4. **Exercise regularly.** Exercise can help improve your mood and energy levels. Aim for at least 30 minutes of moderate-intensity exercise most days of the week.\n",
      "5. **Manage stress.** Stress can take a toll on your physical and mental health, leading to fatigue. Find healthy ways to manage stress, such as yoga, meditation, or spending time with loved ones.\n",
      "6. **See a doctor.** If you're feeling tired for more than two weeks, see a doctor to rule out any underlying medical conditions.\n"
     ]
    }
   ],
   "source": [
    "# sample questions\n",
    "sample_Q = \"3rd degree burns on palms, what to do?\"\n",
    "get_answer(model, sample_Q)\n",
    "\n",
    "sample_Q = \"What to do if you are tired?\"\n",
    "get_answer(model, sample_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF Document\n",
    "This model converts natural language texts to embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pdf\n",
    "# pdf = os.path.join(\"data\", \"nurseslabs-cram-sheet.pdf\") # PDF file\n",
    "pdf = os.path.join(\"data\", \"GAN.pdf\") # PDF file\n",
    "loader = PyPDFLoader(pdf) # PDF loader\n",
    "docs = loader.load() # load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in GAN.pdf: 9\n",
      "5th page: page_content='Theorem 1. The global minimum of the virtual training criterion C(G)is achieved if and only if\\npg=pdata. At that point, C(G)achieves the value −log 4 .\\nProof. Forpg=pdata,D∗\\nG(x) =1\\n2, (consider Eq. 2). Hence, by inspecting Eq. 4 at D∗\\nG(x) =1\\n2, we\\nﬁndC(G) = log1\\n2+ log1\\n2=−log 4 . To see that this is the best possible value of C(G), reached\\nonly forpg=pdata, observe that\\nEx∼pdata[−log 2] + Ex∼pg[−log 2] =−log 4\\nand that by subtracting this expression from C(G) =V(D∗\\nG,G), we obtain:\\nC(G) =−log(4) +KL(\\npdata\\ued79\\ued79\\ued79\\ued79pdata+pg\\n2)\\n+KL(\\npg\\ued79\\ued79\\ued79\\ued79pdata+pg\\n2)\\n(5)\\nwhere KL is the Kullback–Leibler divergence. We recognize in the previous expression the Jensen–\\nShannon divergence between the model’s distribution and the data generating process:\\nC(G) =−log(4) + 2·JSD (pdata∥pg) (6)\\nSince the Jensen–Shannon divergence between two distributions is always non-negative and zero\\nonly when they are equal, we have shown that C∗=−log(4) is the global minimum of C(G)and\\nthat the only solution is pg=pdata, i.e., the generative model perfectly replicating the data generating\\nprocess.\\n4.2 Convergence of Algorithm 1\\nProposition 2. IfGandDhave enough capacity, and at each step of Algorithm 1, the discriminator\\nis allowed to reach its optimum given G, andpgis updated so as to improve the criterion\\nEx∼pdata[logD∗\\nG(x)] +Ex∼pg[log(1−D∗\\nG(x))]\\nthenpgconverges to pdata\\nProof. ConsiderV(G,D ) =U(pg,D)as a function of pgas done in the above criterion. Note\\nthatU(pg,D)is convex in pg. The subderivatives of a supremum of convex functions include the\\nderivative of the function at the point where the maximum is attained. In other words, if f(x) =\\nsupα∈Afα(x)andfα(x)is convex in xfor everyα, then∂fβ(x)∈∂fifβ= arg supα∈Afα(x).\\nThis is equivalent to computing a gradient descent update for pgat the optimal Dgiven the cor-\\nrespondingG.supDU(pg,D)is convex in pgwith a unique global optima as proven in Thm 1,\\ntherefore with sufﬁciently small updates of pg,pgconverges to px, concluding the proof.\\nIn practice, adversarial nets represent a limited family of pgdistributions via the function G(z;θg),\\nand we optimize θgrather thanpgitself. Using a multilayer perceptron to deﬁne Gintroduces\\nmultiple critical points in parameter space. However, the excellent performance of multilayer per-\\nceptrons in practice suggests that they are a reasonable model to use despite their lack of theoretical\\nguarantees.\\n5 Experiments\\nWe trained adversarial nets an a range of datasets including MNIST[23], the Toronto Face Database\\n(TFD) [28], and CIFAR-10 [21]. The generator nets used a mixture of rectiﬁer linear activations [19,\\n9] and sigmoid activations, while the discriminator net used maxout [10] activations. Dropout [17]\\nwas applied in training the discriminator net. While our theoretical framework permits the use of\\ndropout and other noise at intermediate layers of the generator, we used noise as the input to only\\nthe bottommost layer of the generator network.\\nWe estimate probability of the test set data under pgby ﬁtting a Gaussian Parzen window to the\\nsamples generated with Gand reporting the log-likelihood under this distribution. The σparameter\\n5' metadata={'source': 'data/GAN.pdf', 'page': 4}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pages in {os.path.basename(pdf)}: {len(docs)}\")\n",
    "print(f\"5th page: {docs[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "# from langchain.llms import HuggingFaceHub # <-- currently invalid for Q&A task\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter, NLTKTextSplitter, SpacyTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Cassandra, Chroma, FAISS # vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Splitting: split the document into small chunks\n",
    "chunk_size = 500\n",
    "text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained Text Embedding Model\n",
    "device = \"cuda\"\n",
    "query_instruction = \"Represent the query for retrieval: \"\n",
    "embeddings = embedding_model(query_instruction=query_instruction,\n",
    "                             model_kwargs={\"device\": device},\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector database (options: Cassandra, Chroma, FAISS)\n",
    "db = FAISS.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector retrieval from database\n",
    "search_type = \"similarity\"\n",
    "k = 3 # top k similar documents\n",
    "retriever = db.as_retriever(\n",
    "    search_type=search_type,\n",
    "    search_kwargs={\"k\": k}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. One can approximately model all conditionals p(xS|x̸S)whereSis a subset of the indices\n",
      "ofxby training a family of conditional models that share parameters. Essentially, one can use\n",
      "adversarial nets to implement a stochastic extension of the deterministic MP-DBM [11].\n",
      "4.Semi-supervised learning : features from the discriminator or inference net could improve perfor-\n",
      "mance of classiﬁers when limited labeled data is available.\n",
      "5.Efﬁciency improvements: training could be accelerated greatly by divising better methods for\n",
      "coordinating GandDor determining better distributions to sample zfrom during training.\n",
      "This paper has demonstrated the viability of the adversarial modeling framework, suggesting that\n",
      "these research directions could prove useful.\n",
      "Acknowledgments\n",
      "We would like to acknowledge Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume\n",
      "Alain and Jason Yosinski for helpful discussions. Yann Dauphin shared his Parzen window eval-\n",
      "uation code with us. We would like to thank the developers of Pylearn2 [12] and Theano [7, 1],\n",
      "particularly Fr ´ed´eric Bastien who rushed a Theano feature speciﬁcally to beneﬁt this project. Ar-\n",
      "naud Bergeron provided much-needed support with L ATEX typesetting. We would also like to thank\n",
      "CIFAR, and Canada Research Chairs for funding, and Compute Canada, and Calcul Qu ´ebec for\n",
      "providing computational resources. Ian Goodfellow is supported by the 2013 Google Fellowship in\n",
      "Deep Learning. Finally, we would like to thank Les Trois Brasseurs for stimulating our creativity.\n",
      "References\n",
      "[1] Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., and\n",
      "Bengio, Y . (2012). Theano: new features and speed improvements. Deep Learning and Unsupervised\n",
      "Feature Learning NIPS 2012 Workshop.\n",
      "[2] Bengio, Y . (2009). Learning deep architectures for AI . Now Publishers.\n",
      "[3] Bengio, Y ., Mesnil, G., Dauphin, Y ., and Rifai, S. (2013a). Better mixing via deep representations. In\n",
      "ICML’13 .\n",
      "[4] Bengio, Y ., Yao, L., Alain, G., and Vincent, P. (2013b). Generalized denoising auto-encoders as generative\n",
      "models. In NIPS26 . Nips Foundation.\n",
      "[5] Bengio, Y ., Thibodeau-Laufer, E., and Yosinski, J. (2014a). Deep generative stochastic networks trainable\n",
      "by backprop. In ICML’14 .\n",
      "[6] Bengio, Y ., Thibodeau-Laufer, E., Alain, G., and Yosinski, J. (2014b). Deep generative stochastic net-\n",
      "works trainable by backprop. In Proceedings of the 30th International Conference on Machine Learning\n",
      "(ICML’14) .\n",
      "[7] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley,\n",
      "D., and Bengio, Y . (2010). Theano: a CPU and GPU math expression compiler. In Proceedings of the\n",
      "Python for Scientiﬁc Computing Conference (SciPy) . Oral Presentation.\n",
      "[8] Breuleux, O., Bengio, Y ., and Vincent, P. (2011). Quickly generating representative samples from an\n",
      "RBM-derived process. Neural Computation ,23(8), 2053–2073.\n",
      "[9] Glorot, X., Bordes, A., and Bengio, Y . (2011). Deep sparse rectiﬁer neural networks. In AISTATS’2011 .\n",
      "[10] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y . (2013a). Maxout networks.\n",
      "InICML’2013 .\n",
      "[11] Goodfellow, I. J., Mirza, M., Courville, A., and Bengio, Y . (2013b). Multi-prediction deep Boltzmann\n",
      "machines. In NIPS’2013 .\n",
      "[12] Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V ., Mirza, M., Pascanu, R., Bergstra,\n",
      "J., Bastien, F., and Bengio, Y . (2013c). Pylearn2: a machine learning research library. arXiv preprint\n",
      "arXiv:1308.4214 .\n",
      "[13] Gutmann, M. and Hyvarinen, A. (2010). Noise-contrastive estimation: A new estimation principle for\n",
      "unnormalized statistical models. In AISTATS’2010 .\n",
      "[14] Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V ., Nguyen, P.,\n",
      "Sainath, T., and Kingsbury, B. (2012a). Deep neural networks for acoustic modeling in speech recognition.\n",
      "IEEE Signal Processing Magazine ,29(6), 82–97.\n",
      "[15] Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995). The wake-sleep algorithm for unsupervised\n",
      "neural networks. Science ,268, 1558–1161.\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# show top k similar texts retrieved from the vector database\n",
    "similar_texts = retriever.get_relevant_documents(\"ABG Values of CO2\")\n",
    "print(similar_texts[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\", # other options: map_reduce, refine, etc.\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does the paper propose?\n",
      "Answer: A new framework for estimating generative models via an adversarial process\n",
      "Question: Who are the authors?\n",
      "Answer: Ian J. Goodfellow, Jean Pouget-Abadie∗, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair†, Aaron Courville, Yoshua Bengio\n"
     ]
    }
   ],
   "source": [
    "query = \"What does the paper propose?\"\n",
    "response = QA_chain(query)\n",
    "print(f\"Question: {query}\\nAnswer: {response['result']}\")\n",
    "\n",
    "query = \"Who are the authors?\"\n",
    "response = QA_chain(query)\n",
    "print(f\"Question: {query}\\nAnswer: {response['result']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
